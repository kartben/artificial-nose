/* Generated by Edge Impulse
*
* Permission is hereby granted, free of charge, to any person obtaining a copy
* of this software and associated documentation files (the "Software"), to deal
* in the Software without restriction, including without limitation the rights
* to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
* copies of the Software, and to permit persons to whom the Software is
* furnished to do so, subject to the following conditions:
*
* The above copyright notice and this permission notice shall be included in
* all copies or substantial portions of the Software.
*
* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
* AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
* OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
* SOFTWARE.
*/
// Generated on: 28.07.2021 18:17:29

#include <stdio.h>
#include <stdlib.h>
#include <vector>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#endif

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

constexpr int kTensorArenaSize = 304;

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

TfLiteContext ctx{};
TfLiteTensor tflTensors[11];
TfLiteEvalTensor tflEvalTensors[11];
TfLiteRegistration registrations[OP_LAST];
TfLiteNode tflNodes[4];

const TfArray<2, int> tensor_dimension0 = { 2, { 1,20 } };
const ALIGN(8) float tensor_data1[8] = { -0.0042316876351833344, 0.12219603359699249, 0.33265352249145508, 0.072677433490753174, 0, -1.0748348236083984, 0, 0.58984112739562988, };
const TfArray<1, int> tensor_dimension1 = { 1, { 8 } };
const ALIGN(8) float tensor_data2[4] = { 0.31059560179710388, 1.4324949979782104, -2.019636869430542, -0.26358455419540405, };
const TfArray<1, int> tensor_dimension2 = { 1, { 4 } };
const ALIGN(8) float tensor_data3[9] = { -0.56593221426010132, 0.63127505779266357, 0.60026317834854126, 0.67331206798553467, -0.24197694659233093, 0.25224986672401428, -1.0071916580200195, -2.4819159507751465, 2.4610152244567871, };
const TfArray<1, int> tensor_dimension3 = { 1, { 9 } };
const ALIGN(8) float tensor_data4[8*20] = { 
  -0.34339305758476257, 0.136426642537117, -0.34784296154975891, 0.2529272735118866, 0.30906733870506287, -0.27980580925941467, 0.16469310224056244, 0.26878663897514343, 0.28271308541297913, -0.26007571816444397, -0.079825013875961304, 0.28021025657653809, -0.023215459659695625, 0.40403401851654053, -0.14928759634494781, -0.39183172583580017, -0.15109667181968689, -0.054285377264022827, -0.18281190097332001, -0.20165540277957916, 
  0.32223212718963623, 0.25693440437316895, 0.036395691335201263, 0.00022596382768824697, -4.6814413070678711, -1.1323243379592896, -1.0853680372238159, -1.5842723846435547, -1.2140541076660156, -2.3191530704498291, 0.58995586633682251, 0.1017998605966568, 0.89234781265258789, 0.66593402624130249, -3.9200263023376465, 0.75556284189224243, 0.43065658211708069, 0.53710561990737915, 0.61787796020507812, -2.2246594429016113, 
  -0.89856702089309692, -1.2500835657119751, -1.2177838087081909, -0.48251190781593323, -2.285635232925415, -1.0321642160415649, -1.0238423347473145, -0.39760762453079224, -0.83860152959823608, -3.5369415283203125, 0.70701903104782104, 1.1450090408325195, 0.97522670030593872, 0.84271121025085449, -2.0221178531646729, -0.21207086741924286, 0.3741266131401062, 0.21182210743427277, 0.12085288017988205, -0.70903360843658447, 
  1.0703129768371582, 1.9074337482452393, 1.3782742023468018, 1.9629082679748535, -0.29429081082344055, -0.17385061085224152, 0.14934031665325165, 0.5334429144859314, 0.083539970219135284, 1.3220000267028809, 0.33779066801071167, 0.26492571830749512, 0.31379321217536926, 0.63852888345718384, 0.67365133762359619, 0.1697397381067276, 0.60592067241668701, 0.49313387274742126, 0.062984488904476166, -0.51411843299865723, 
  0.0042048394680023193, 0.17261356115341187, -0.31747359037399292, 0.18568170070648193, 0.39215254783630371, -0.27522996068000793, 0.078386068344116211, 0.055473864078521729, -0.43834847211837769, 0.077671647071838379, 0.14544522762298584, 0.35269105434417725, 0.039219915866851807, 0.21100401878356934, -0.0026859939098358154, -0.34993737936019897, 0.12205779552459717, -0.3338475227355957, -0.091024219989776611, -0.21850088238716125, 
  1.2172428369522095, 1.0789182186126709, 1.0483441352844238, 1.0750483274459839, -5.2844481468200684, -1.2838033437728882, -1.3042691946029663, -1.400174617767334, -0.97372370958328247, -3.5060544013977051, 0.19342422485351562, 0.27201712131500244, 0.62304341793060303, 0.18186546862125397, -4.139470100402832, 0.11701682955026627, 0.23526366055011749, 0.37522506713867188, -0.16808156669139862, -2.9185829162597656, 
  -0.3422415554523468, -0.27076864242553711, -0.45012345910072327, -0.37930169701576233, -0.096822649240493774, -0.057601302862167358, 0.45493102073669434, 0.19234073162078857, -0.34356009960174561, 0.39975214004516602, -0.1768038272857666, 0.21693700551986694, 0.10293585062026978, -0.15485846996307373, 0.17357295751571655, 0.1341291069984436, 0.23303842544555664, -0.10855644941329956, -0.014815241098403931, -0.31105488538742065, 
  -0.97978031635284424, -1.0969393253326416, -0.96635723114013672, -0.57804101705551147, -1.830286979675293, -1.1974836587905884, -0.96880930662155151, -0.76666909456253052, -0.97067815065383911, -2.7524154186248779, 0.56883478164672852, 0.84113740921020508, 1.0690792798995972, 1.3948720693588257, -2.0953094959259033, 0.58366334438323975, 0.24370786547660828, 0.58415526151657104, 0.83669382333755493, -1.4394209384918213, 
};
const TfArray<2, int> tensor_dimension4 = { 2, { 8,20 } };
const ALIGN(8) float tensor_data5[4*8] = { 
  -0.42954376339912415, 0.91494500637054443, -3.0778369903564453, 1.9869433641433716, -0.21008232235908508, 1.7002332210540771, -0.36648118495941162, -1.6339846849441528, 
  -0.44366419315338135, 0.71885710954666138, 2.1813204288482666, -0.20505009591579437, 0.60952872037887573, -1.6283568143844604, -0.54040974378585815, 1.3761881589889526, 
  -0.52822482585906982, 2.694359302520752, 1.5470243692398071, -0.15087854862213135, 0.44061118364334106, 2.9055874347686768, 0.078051388263702393, 1.5050514936447144, 
  -0.44820290803909302, -5.2032918930053711, 0.099004447460174561, 0.44067290425300598, 0.21780377626419067, -1.6612075567245483, -0.37849539518356323, 0.19973747432231903, 
};
const TfArray<2, int> tensor_dimension5 = { 2, { 4,8 } };
const ALIGN(8) float tensor_data6[9*4] = { 
  -1.5833672285079956, 0.63456821441650391, 0.66675853729248047, -0.30289554595947266, 
  -1.1866174936294556, 0.44560691714286804, 0.4461577832698822, -0.43256232142448425, 
  0.78893536329269409, -2.4381012916564941, -4.2619304656982422, -2.6198034286499023, 
  -5.9493651390075684, 2.0979721546173096, 0.38662007451057434, -0.17981842160224915, 
  0.21000024676322937, -1.9928075075149536, -2.1283459663391113, 2.4860658645629883, 
  0.49810820817947388, -3.3107051849365234, -0.081480495631694794, -4.5242471694946289, 
  -0.29967018961906433, -2.2383222579956055, 0.87519693374633789, -0.79649150371551514, 
  0.42656800150871277, -5.5784802436828613, 0.77025818824768066, -2.7584495544433594, 
  0.54528206586837769, 0.31010535359382629, -1.6587440967559814, -6.3535199165344238, 
};
const TfArray<2, int> tensor_dimension6 = { 2, { 9,4 } };
const TfArray<2, int> tensor_dimension7 = { 2, { 1,8 } };
const TfArray<2, int> tensor_dimension8 = { 2, { 1,4 } };
const TfArray<2, int> tensor_dimension9 = { 2, { 1,9 } };
const TfArray<2, int> tensor_dimension10 = { 2, { 1,9 } };
const TfLiteFullyConnectedParams opdata0 = { kTfLiteActRelu, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs0 = { 3, { 0,4,1 } };
const TfArray<1, int> outputs0 = { 1, { 7 } };
const TfLiteFullyConnectedParams opdata1 = { kTfLiteActRelu, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs1 = { 3, { 7,5,2 } };
const TfArray<1, int> outputs1 = { 1, { 8 } };
const TfLiteFullyConnectedParams opdata2 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs2 = { 3, { 8,6,3 } };
const TfArray<1, int> outputs2 = { 1, { 9 } };
const TfLiteSoftmaxParams opdata3 = { 1 };
const TfArray<1, int> inputs3 = { 1, { 9 } };
const TfArray<1, int> outputs3 = { 1, { 10 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension0, 80, },
  { kTfLiteMmapRo, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 32, },
  { kTfLiteMmapRo, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 16, },
  { kTfLiteMmapRo, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 36, },
  { kTfLiteMmapRo, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 640, },
  { kTfLiteMmapRo, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 128, },
  { kTfLiteMmapRo, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 144, },
  { kTfLiteArenaRw, tensor_arena + 80, (TfLiteIntArray*)&tensor_dimension7, 32, },
  { kTfLiteArenaRw, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension8, 16, },
  { kTfLiteArenaRw, tensor_arena + 48, (TfLiteIntArray*)&tensor_dimension9, 36, },
  { kTfLiteArenaRw, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension10, 36, },
};const NodeInfo_t nodeData[] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_SOFTMAX, },
};
static std::vector<void*> overflow_buffers;
static void * AllocatePersistentBuffer(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  if (current_location - bytes < tensor_boundary) {
    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers.push_back(ptr);
    return ptr;
  }

  current_location -= bytes;

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static std::vector<scratch_buffer_t> scratch_buffers;

static TfLiteStatus RequestScratchBufferInArena(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBuffer(ctx, b.bytes);
  if (!b.ptr) {
    return kTfLiteError;
  }

  scratch_buffers.push_back(b);

  *buffer_idx = scratch_buffers.size() - 1;

  return kTfLiteOk;
}

static void* GetScratchBuffer(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > static_cast<int>(scratch_buffers.size()) - 1) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static TfLiteTensor* GetTensor(const struct TfLiteContext* context,
                               int tensor_idx) {
  return &tflTensors[tensor_idx];
}

static TfLiteEvalTensor* GetEvalTensor(const struct TfLiteContext* context,
                                       int tensor_idx) {
  return &tflEvalTensors[tensor_idx];
}

} // namespace

TfLiteStatus trained_model_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;
  ctx.AllocatePersistentBuffer = &AllocatePersistentBuffer;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArena;
  ctx.GetScratchBuffer = &GetScratchBuffer;
  ctx.GetTensor = &GetTensor;
  ctx.GetEvalTensor = &GetEvalTensor;
  ctx.tensors = tflTensors;
  ctx.tensors_size = 11;
  for(size_t i = 0; i < 11; ++i) {
    tflTensors[i].type = kTfLiteFloat32;
    tflEvalTensors[i].type = kTfLiteFloat32;
    tflTensors[i].is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    tflTensors[i].allocation_type = tensorData[i].allocation_type;
#else
    tflTensors[i].allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
    tflTensors[i].bytes = tensorData[i].bytes;
    tflTensors[i].dims = tensorData[i].dims;
    tflEvalTensors[i].dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    if(tflTensors[i].allocation_type == kTfLiteArenaRw){
      uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

     tflTensors[i].data.data =  start;
     tflEvalTensors[i].data.data =  start;
    }
    else{
       tflTensors[i].data.data = tensorData[i].data;
       tflEvalTensors[i].data.data = tensorData[i].data;
    }
#else
    tflTensors[i].data.data = tensorData[i].data;
    tflEvalTensors[i].data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
    tflTensors[i].quantization.type = kTfLiteNoQuantization;
    if (tflTensors[i].allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tflTensors[i].data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }
  if (tensor_boundary > current_location /* end of arena size */) {
    printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for(size_t i = 0; i < 4; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
    tflNodes[i].custom_initial_data = nullptr;
    tflNodes[i].custom_initial_data_size = 0;
    if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }
  for(size_t i = 0; i < 4; ++i) {
    if (registrations[nodeData[i].used_op_index].prepare) {
      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
  }
  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0, 
};
TfLiteTensor* trained_model_input(int index) {
  return &ctx.tensors[inTensorIndices[index]];
}

static const int outTensorIndices[] = {
  10, 
};
TfLiteTensor* trained_model_output(int index) {
  return &ctx.tensors[outTensorIndices[index]];
}

TfLiteStatus trained_model_invoke() {
  for(size_t i = 0; i < 4; ++i) {
    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus trained_model_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif
  scratch_buffers.clear();
  for (size_t ix = 0; ix < overflow_buffers.size(); ix++) {
    free(overflow_buffers[ix]);
  }
  overflow_buffers.clear();
  return kTfLiteOk;
}
